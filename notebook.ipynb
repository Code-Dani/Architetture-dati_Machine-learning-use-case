{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Architetture dati - progetto use case \"Data management for Machine Learning\"",
   "id": "68bb234da639f650"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "15b9c261af3a9a76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import time"
   ],
   "id": "5b22dd89187e2c6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Inizializzazione del dataset load_breast_cancer()\n",
    "Il dataset è ottimo per questo progetto dato il numero elavato di features (30).\n",
    "\n",
    "\n",
    "Il dataset contiene 30 caratteristiche (attributi) che descrivono le proprietà dei nuclei delle cellule tumorali ottenute tramite immagini di aspirato con ago sottile (FNA) di una massa al seno. Le caratteristiche sono suddivise in tre gruppi principali: media, errore standard, e i \"peggiori\" (cioè, il valore massimo) di queste caratteristiche per ogni immagine.\n",
    "\n",
    "\n",
    "Il dataset include anche una variabile di destinazione (target) binaria che indica se il tumore è maligno (0) o benigno (1).\n",
    "\n",
    "Inoltre questo dataset risulta comodo in quanto disponibile direttamente da sklearn.datasets"
   ],
   "id": "d81f23dd5b936828"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('./Dataset/breast-cancer-augmented.csv')\n",
    "data.head()\n",
    "X = data.drop(columns=['diagnosis'])\n",
    "Y = data['diagnosis'].map({'M': 0 , 'B': 1})\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = Y\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "df.head()\n"
   ],
   "id": "4fbb4c0ac4a1223a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Analisi esplorativa dei dati\n",
    "Vado adesso ad eseguire un analisi esplorativa dei dati per capire meglio il dataset."
   ],
   "id": "9b4d96bed1f2188f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Verifica del numero di features e di istanze\n",
    "Come prima cosa verifichiamo il numero di features e di istanze: 30 e 569 rispettivamente.\n",
    "\n",
    "\n",
    "Il target è binario:\n",
    "* 0 = Maligno\n",
    "* 1 = Benigno"
   ],
   "id": "e63f07045fe99479"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#print number of features\n",
    "print(f\"Number of features: {len(data.columns)}\")\n",
    "#print number of istances\n",
    "print(f\"Number of istances: {len(df)}\")\n",
    "\n",
    "df.head()"
   ],
   "id": "8da7fdb9facadeb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "977130a1836da746"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Distribuzione della Diagnosi del Tumore\n",
    "\n",
    "Questo codice genera un grafico a barre che rappresenta la distribuzione della variabile target \"target\" nel dataset \"df\". La variabile target indica la diagnosi del tumore, con 0 che indica un tumore maligno e 1 che indica un tumore benigno.\n",
    "\n",
    "Il grafico è suddiviso in due barre:\n",
    "\n",
    "* **Barra rossa:** Rappresenta la frequenza dei tumori maligni.\n",
    "* **Barra blu:** Rappresenta la frequenza dei tumori benigni.\n",
    "\n",
    "L'asse x del grafico rappresenta la diagnosi del tumore (0 = maligno, 1 = benigno). L'asse y del grafico rappresenta la frequenza delle diverse diagnosi.\n",
    "\n",
    "**Interpretazione:**\n",
    "\n",
    "Il grafico mostra che nel dataset \"Breast Cancer Wisconsin ...\" ci sono più tumori benigni che tumori maligni. La frequenza dei tumori maligni è circa il 37.2%, mentre la frequenza dei tumori benigni è circa il 62.7%.\n",
    "\n",
    "**Informazioni aggiuntive:**\n",
    "\n",
    "* Il codice utilizza la libreria seaborn per generare il grafico a barre.\n",
    "* La funzione `sns.countplot()` è utilizzata per creare il grafico a barre.\n",
    "* L'argomento `data=df` indica il dataset da utilizzare per generare il grafico.\n",
    "* L'argomento `x='target'` indica la variabile da utilizzare per l'asse x del grafico.\n",
    "* L'argomento `palette=['red', 'blue']` indica i colori da utilizzare per le barre del grafico.\n",
    "* L'argomento `hue='target'` indica che le barre del grafico devono essere suddivise in base al valore della variabile target.\n",
    "* L'argomento `dodge=False` indica che le barre del grafico non devono essere separate.\n",
    "* L'argomento `legend=False` indica che la legenda del grafico non deve essere visualizzata.\n",
    "* Il metodo `plt.title()` è utilizzato per impostare il titolo del grafico.\n",
    "* Il metodo `plt.xlabel()` è utilizzato per impostare l'etichetta dell'asse x del grafico.\n",
    "* Il metodo `plt.ylabel()` è utilizzato per impostare l'etichetta dell'asse y del grafico.\n",
    "* Il metodo `plt.show()` è utilizzato per visualizzare il grafico."
   ],
   "id": "aebe5b2ecdb32411"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ottenere il conteggio e le percentuali per la variabile \"target\"\n",
    "conteggio_percentuali = df['target'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Stampare le percentuali\n",
    "print(\"Percentuali di diagnosi:\")\n",
    "print(conteggio_percentuali)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='target', palette=['red', 'blue'], hue='target', dodge=False, legend=False)\n",
    "plt.title('Distribuzione della Diagnosi del Tumore')\n",
    "plt.xlabel('Diagnosi (0 = Maligno, 1 = Benigno)')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.show()"
   ],
   "id": "69951cc2a26c0f5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 Matrice di Correlazione\n",
    "La matrice di correlazione è un grafico che mostra le relazioni tra le variabili in un dataset. Permette di identificare facilmente le coppie di variabili che presentano una forte correlazione, sia positiva che negativa.\n",
    "\n",
    "**Interpretazione:**\n",
    "\n",
    "* **Colori:**\n",
    "    * Rosso intenso: Correlazione positiva forte (le variabili aumentano o diminuiscono insieme).\n",
    "    * Blu intenso: Correlazione negativa forte (le variabili aumentano in una direzione e diminuiscono nell'altra).\n",
    "    * Bianco/grigio chiaro: Correlazione debole o assente (le variabili non mostrano una relazione lineare significativa).\n",
    "* **Valori:** I numeri all'interno dei quadrati indicano il coefficiente di correlazione, che varia da -1 a 1.\n",
    "\n",
    "**Cosa possiamo dedurre:**\n",
    "\n",
    "* Identificare relazioni tra le variabili.\n",
    "* Comprendere la direzione della relazione (positiva o negativa).\n",
    "* Valutare l'intensità della relazione (forte o debole).\n",
    "\n",
    "**Importante:**\n",
    "\n",
    "* Correlazione non implica causazione.\n",
    "* Interpretare nel contesto del dataset specifico.\n",
    "\n",
    "**Osservazioni:**\n",
    "\n",
    "* Alcune variabili sono fortemente correlate tra loro, come \"mean radius\" e \"mean texture\".\n",
    "* Altre variabili non sono correlate tra loro, come \"radius error\" e \"worst radius\".\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "264e18698ed958b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=0.2)\n",
    "plt.title('Matrice di Correlazione')\n",
    "plt.show()\n"
   ],
   "id": "567bb9080ff4e36d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.4 Importanza delle Caratteristiche nel Dataset \"Breast Cancer Wisconsin\"\n",
    "\n",
    "Questo grafico a barre rappresenta l'importanza delle caratteristiche nel dataset \"Breast Cancer Wisconsin\". L'importanza è stata calcolata utilizzando un algoritmo di Random Forest.\n",
    "\n",
    "Le caratteristiche sono ordinate in base alla loro importanza, con la caratteristica più importante in alto. I valori di importanza sono rappresentati da barre colorate.\n",
    "\n",
    "Dall'analisi del grafico è possibile osservare che alcune caratteristiche sono più importanti di altre per la classificazione dei tumori al seno. Quelle più importanti sono:\n",
    "\n",
    "* **worst area**\n",
    "* **worst concave points**\n",
    "* **mean concave points**\n",
    "* **worst radius**\n",
    "* **worst perimeter**\n",
    "\n",
    "Queste caratteristiche sono probabilmente quelle che forniscono più informazioni sulla natura del tumore e sulla sua probabilità di essere maligno.\n",
    "\n",
    "L'analisi dell'importanza delle caratteristiche può essere utile per selezionare le caratteristiche più importanti da utilizzare in un modello di machine learning e per comprendere meglio i fattori che influenzano la classificazione dei tumori al seno.\n",
    "\n",
    "Nei grafici successivi andremo ad analizzare queste 5 feature più importanti.\n"
   ],
   "id": "4ebee5446d80309a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dividere i dati in caratteristiche (X) e target (y)\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# Addestrare un modello di RandomForest\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Ottenere l'importanza delle caratteristiche\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualizzare l'importanza delle caratteristiche\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis', hue='Feature', dodge=False, legend=False)\n",
    "plt.title('Importanza delle Caratteristiche')\n",
    "plt.show()\n"
   ],
   "id": "a520db07d5aa013c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Creo una lista con le prime 5 feature più importanti\n",
    "topFeaturesByImportance = feature_importance_df[:5]['Feature'].values\n",
    "print(topFeaturesByImportance)\n"
   ],
   "id": "ce405e8fb2865722",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.5 Distribuzione delle Caratteristiche più Importanti nel Dataset \"Breast Cancer Wisconsin\"\n",
    "\n",
    "Questo set di istogrammi mostra la distribuzione delle cinque caratteristiche più importanti nel dataset \"Breast Cancer Wisconsin\". Le caratteristiche sono state identificate utilizzando un algoritmo di Random Forest nel precedente passaggio.\n",
    "\n",
    "Ogni istogramma mostra la distribuzione di una caratteristica per i tumori benigni (colore rosso) e maligni (colore blu). La densità di probabilità è rappresentata da una curva tratteggiata.\n",
    "\n",
    "**Interpretazione dettagliata:**\n",
    "* Per tutti i grafici possiamo notare come la distribuzione sia piuttosto marcata tra i due tipi di tumore, infatti queste cinque feature non a caso sono considerate le più importanti, appunto per questa loro caratteristica, possiamo notare che a sinistra dei grafici è presente una concentrazione più marcata di tumori benigni, mentre a destra è presente una concentrazione più marcata di tumori maligni.\n",
    "**Considerazioni generali:**\n",
    "\n",
    "* L'analisi di questi istogrammi conferma che le **caratteristiche più importanti** per la classificazione dei tumori al seno sono quelle relative alla **forma e alla dimensione del tumore**. Queste caratteristiche presentano una distribuzione differenziata tra i tumori benigni e maligni, suggerendo che possono essere utilizzate per distinguere tra i due tipi di tumore.\n",
    "* L'analisi della distribuzione delle caratteristiche può essere utile per:\n",
    "    * Comprendere meglio la relazione tra le caratteristiche del tumore e la sua natura (benigno o maligno).\n",
    "    * Identificare potenziali biomarcatori per la diagnosi precoce del cancro al seno.\n",
    "    * Sviluppare algoritmi di machine learning più efficaci per la classificazione dei tumori al seno.\n",
    "\n"
   ],
   "id": "7d2be3ad453c79bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = topFeaturesByImportance # Prendo le 5 feature più importanti\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sns.histplot(data=df, x=feature, hue='target', element='step', palette=['red', 'blue'], kde=True)\n",
    "    plt.title(f'Distribuzione di {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6d518175fda93bca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.6 Box Plot delle Caratteristiche più Importanti nel Dataset \"Breast Cancer Wisconsin\"\n",
    "\n",
    "L'immagine mostra una serie di box plot che rappresentano la distribuzione di diverse caratteristiche per due diversi obiettivi (\"target\"). I box plot sono suddivisi in due righe e tre colonne. Ogni box plot rappresenta la distribuzione di una singola caratteristica per un singolo obiettivo.\n",
    "\n",
    "**Elementi del box plot:**\n",
    "\n",
    "* **Scatola:** La scatola rappresenta la distribuzione centrale dei dati. La linea centrale all'interno della scatola rappresenta la mediana.\n",
    "* **Whisker:** I baffi si estendono dalla scatola fino al massimo e al minimo valore dei dati che non sono considerati outlier.\n",
    "* **Outlier:** I punti dati che si trovano al di fuori dei baffi sono considerati outlier e sono rappresentati da punti singoli.\n",
    "\n",
    "**Interpretazione dei box plot:**\n",
    "\n",
    "* **Posizione della mediana:** La posizione della mediana all'interno della scatola indica la simmetria della distribuzione dei dati. Se la mediana è al centro della scatola, la distribuzione è simmetrica. Se la mediana è spostata verso un bordo della scatola, la distribuzione è asimmetrica.\n"
   ],
   "id": "7a066f1c213f4a8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analisi esplorativa - Box Plot delle Caratteristiche\n",
    "features = topFeaturesByImportance\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sns.boxplot(x='target', y=feature, data=df, palette=['red', 'blue'], hue='target', dodge=False, legend=False)\n",
    "    plt.title(f'Box Plot di {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b721114e311adb75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Eseguo l'algoritmo Decision Tree senza rumore",
   "id": "41906b57ea86eab2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1 Split del dataset\n",
    "Abbiamo scelto di dividere il dataset in training set (70%) e test set (30%)."
   ],
   "id": "4b5c93efb764c882"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split del dataset in train e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Dimensione del training set (70%):\", X_train.shape)\n",
    "print(\"Dimensione del test set (30%):\", X_test.shape)"
   ],
   "id": "29c2b6bfa5595c84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Distribuzione dei target positivi e negativi nei set di training e test\n",
    "Nei grafici sopra riportati, possiamo osservare la distribuzione delle classi del target nei set di training e test. \n",
    "\n",
    "- **Training Set**: \n",
    "  - Classe `1`: Rappresenta il 37.4% dei dati del training set.\n",
    "  - Classe `0`: Rappresenta il 62.6% dei dati del training set.\n",
    "\n",
    "- **Test Set**: \n",
    "  - Classe `1`: Rappresenta il 36.8% dei dati del test set.\n",
    "  - Classe `0`: Rappresenta il 63.2% dei dati del test set.\n",
    "\n",
    "La distribuzione delle classi è simile tra i due set, con una leggera predominanza della classe `0` in entrambi. Questo indica che il campionamento casuale effettuato con `train_test_split` ha mantenuto una distribuzione proporzionale delle classi tra training e test set, garantendo una buona rappresentatività dei dati nel processo di validazione del modello.\n"
   ],
   "id": "b8198b592d719804"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Conta le occorrenze di ogni classe nel training set e nel test set\n",
    "train_counts = y_train.value_counts()\n",
    "test_counts = y_test.value_counts()\n",
    "\n",
    "# Calcola le percentuali\n",
    "train_percentages = (train_counts / train_counts.sum()) * 100\n",
    "test_percentages = (test_counts / test_counts.sum()) * 100\n",
    "\n",
    "# Crea una figura e assi per i due grafici\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Grafico per il training set\n",
    "train_counts.plot(kind='bar', ax=ax[0])\n",
    "for i, count in enumerate(train_counts):\n",
    "    ax[0].text(i, count, f'{train_percentages[i]:.1f}%', ha='center', va='bottom')\n",
    "ax[0].set_title('Distribuzione del Target nel Training Set')\n",
    "ax[0].set_xlabel('Classi')\n",
    "ax[0].set_ylabel('Frequenza')\n",
    "\n",
    "# Grafico per il test set\n",
    "test_counts.plot(kind='bar', ax=ax[1])\n",
    "for i, count in enumerate(test_counts):\n",
    "    ax[1].text(i, count, f'{test_percentages[i]:.1f}%', ha='center', va='bottom')\n",
    "ax[1].set_title('Distribuzione del Target nel Test Set')\n",
    "ax[1].set_xlabel('Classi')\n",
    "ax[1].set_ylabel('Frequenza')\n",
    "\n",
    "# Mostra i grafici\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "1cd33dd51cbec3bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2 Modello Decision tree",
   "id": "95e57724eacc4b20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.2.1 Addestramento del modello Decision tree",
   "id": "c81c7eb8fe53a969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creiamo e addestriamo il modello di Decision Tree\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ],
   "id": "3f68ada0fd90d036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.2.2 Valutazione del modello SVM",
   "id": "de28b8e555467bd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Avvio cronometro\n",
    "start_time = time.time()\n",
    "\n",
    "# Facciamo previsioni sul test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Stoppo cronometro\n",
    "end_time = time.time()\n",
    "\n",
    "# Valutiamo le performance del modello\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Calcola e stampa il classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Calcola la matrice di confusione\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "elapsed_time_notModifiedDataset = end_time - start_time\n",
    "print(f\"Tempo trascorso: {elapsed_time_notModifiedDataset:.4f} secondi\")\n"
   ],
   "id": "72f79dcccbc01cd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Valutazione della confusion matrix",
   "id": "674a8777ae563634"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualizza la matrice di confusione con seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "28806497d5c98185",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4 Classification report",
   "id": "1e058c1a6d9912d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ],
   "id": "60fb2f9e6eb87646",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Aggiunta di rumore al dataset",
   "id": "a6306e02b73796b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Metodo introduzione dati mancanti",
   "id": "def57ed7643d3264"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def introduce_missing_data_custom(dataset, columns, percentage):\n",
    "    \"\"\"\n",
    "    Introduce valori nulli in un dataset specificando le colonne e la percentuale di dati da annullare.\n",
    "\n",
    "    :param dataset: DataFrame su cui operare.\n",
    "    :param columns: Lista delle colonne su cui introdurre i valori nulli.\n",
    "    :param percentage: Percentuale dei dati da annullare (0-1).\n",
    "    :return: DataFrame modificato.\n",
    "    \"\"\"\n",
    "    # Calcola il numero di righe da annullare in base alla percentuale\n",
    "    num_rows_to_null = int(len(dataset) * percentage)\n",
    "\n",
    "    # Seleziona casualmente le righe da annullare\n",
    "    rows_to_null = np.random.choice(dataset.index, num_rows_to_null, replace=False)\n",
    "    #print(\"Vado a sporcare queste righe: \", rows_to_null)\n",
    "    \n",
    "    # Imposta i valori a NaN per le colonne specificate nelle righe selezionate\n",
    "    dataset.loc[rows_to_null, columns] = np.nan\n",
    "\n",
    "    return dataset"
   ],
   "id": "a340d1038b2ff683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2 Metodo introduzione outliers",
   "id": "ea1256e24544a042"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def introduce_outliers(dataset, columns, percentage):\n",
    "    \"\"\"\n",
    "    Introduce outliers in un dataset specificando le colonne e la percentuale di dati da modificare.\n",
    "\n",
    "    :param dataset: DataFrame su cui operare.\n",
    "    :param columns: Lista delle colonne su cui introdurre gli outliers.\n",
    "    :param percentage: Percentuale dei dati da modificare (0-1).\n",
    "    :return: DataFrame modificato.\n",
    "    \"\"\"\n",
    "    # Calcola il numero di righe da modificare in base alla percentuale\n",
    "    num_rows_to_change = int(len(dataset) * percentage)\n",
    "\n",
    "    # Seleziona casualmente le righe da modificare\n",
    "    rows_to_change = np.random.choice(dataset.index, num_rows_to_change, replace=False)\n",
    "    #print(\"Vado a modificare queste righe: \", rows_to_change)\n",
    "\n",
    "    # Per ogni riga selezionata, aggiungi un outlier alle colonne specificate\n",
    "    for idx in rows_to_change:\n",
    "        for column in columns:\n",
    "            # Calcola un outlier come media + 5 * deviazione standard della colonna\n",
    "            outlier_value = dataset[column].mean() + 5 * dataset[column].std()\n",
    "            dataset.at[idx, column] = outlier_value\n",
    "\n",
    "    return dataset"
   ],
   "id": "8712a7bd8e6a8405",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3 Metodo introduzione righe duplicate",
   "id": "ab70809536601486"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def introduce_duplicate_rows(dataset, percentage, y_train_spor):\n",
    "    \"\"\"\n",
    "    Introduce righe duplicate in un dataset specificando la percentuale di righe da duplicare.\n",
    "    Duplica anche le etichette corrispondenti in y_train_sporcata.\n",
    "\n",
    "    :param dataset: DataFrame su cui operare.\n",
    "    :param percentage: Percentuale di righe da duplicare (0-1).\n",
    "    :param y_train_sporcata: Serie delle etichette corrispondenti.\n",
    "    :return: DataFrame e Serie modificati.\n",
    "    \"\"\"\n",
    "    # Calcola il numero di righe da duplicare in base alla percentuale\n",
    "    num_rows_to_duplicate = int(len(dataset) * percentage)\n",
    "\n",
    "    # Seleziona casualmente le righe da duplicare\n",
    "    rows_to_duplicate = np.random.choice(dataset.index, num_rows_to_duplicate, replace=False)\n",
    "\n",
    "    # Duplica le righe selezionate\n",
    "    duplicated_rows = dataset.loc[rows_to_duplicate]\n",
    "    dataset = pd.concat([dataset, duplicated_rows], ignore_index=True)\n",
    "\n",
    "    # Duplica le etichette corrispondenti\n",
    "    duplicated_labels = y_train_spor.loc[rows_to_duplicate]\n",
    "    y_train_spor = pd.concat([y_train_spor, duplicated_labels], ignore_index=True)\n",
    "\n",
    "    return dataset, y_train_spor"
   ],
   "id": "58eea7938ba83bfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_feature_distribution_comparison(clean_df, noisy_df, feature_columns, top5Feature):\n",
    "    \"\"\"\n",
    "    Confronta graficamente la distribuzione delle feature tra il dataset pulito e quello sporcato.\n",
    "\n",
    "    :param clean_df: DataFrame del dataset pulito.\n",
    "    :param noisy_df: DataFrame del dataset sporcato.\n",
    "    :param feature_columns: Colonne delle feature da confrontare.\n",
    "    :param top5Feature: Lista delle top 5 feature da mostrare.\n",
    "    \"\"\"\n",
    "    # Crea copie dei DataFrame per evitare di modificare gli originali\n",
    "    clean_df_copy = clean_df.copy()\n",
    "    noisy_df_copy = noisy_df.copy()\n",
    "\n",
    "    # Aggiungi una colonna per indicare lo stato (pulito o sporcato)\n",
    "    clean_df_copy['status'] = 'clean'\n",
    "    noisy_df_copy['status'] = 'noisy'\n",
    "\n",
    "    # Seleziona solo le colonne delle top 5 feature\n",
    "    feature_columns_to_plot = [col for col in feature_columns if col in top5Feature]\n",
    "\n",
    "    # Concatena i due dataset\n",
    "    combined_df = pd.concat([clean_df_copy, noisy_df_copy], ignore_index=True)\n",
    "\n",
    "    # Calcola il numero di righe e colonne dei subplot in base al numero di feature da plottare\n",
    "    num_features = len(feature_columns_to_plot)\n",
    "    num_rows = (num_features + 2) // 3  # Calcola il numero di righe necessarie (3 colonne per riga)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(15, 5 * num_rows))  # Altezza ridotta per ridurre la dimensione complessiva del grafico\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    for i, column in enumerate(feature_columns_to_plot, 1):\n",
    "        plt.subplot(num_rows, 3, i)\n",
    "        sns.boxplot(x='status', y=column, data=combined_df)\n",
    "        plt.title(column)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.suptitle('Confronto tra Dataset Pulito e Sporcato', y=1.02, fontsize=16, ha='center')\n",
    "    plt.show()"
   ],
   "id": "6d1b4207eb0c286f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "def plot_confusion_matrix(model):\n",
    "    cm = confusion_matrix(y_test , y_pred_prob[: , 1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()"
   ],
   "id": "d77af57891758421",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Esecuzione dell'algoritmo Decision Tree con rumore dinamico dal 10% al 100%\n",
    "Il rumore viene introdotto sul dataset X_test, che abbiamo creato in precedenza e solo sulle top 5 colonne più importanti che vengono calcolate ad inizio notebook nel paragrafo 2.4."
   ],
   "id": "cc6472e7890bcdf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "percentuali_rumore = [0.01,0.02,0.03,0.5,1]",
   "id": "4a2400ef6ba6b1fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Esecuzione Decision Tree con aggiunta di valori nulli",
   "id": "ae1e397fc4f84adb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aggiungi le metriche ROC al dizionario delle metriche\n",
    "metricsNUll = {\n",
    "    'percentuale': [],\n",
    "    'accuracy': [],\n",
    "    'f1_score': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'fpr': [],   # False Positive Rate\n",
    "    'tpr': [],   # True Positive Rate\n",
    "    'roc_auc': [] # Area Under the Curve\n",
    "}\n",
    "datasetSporcatoNULL = {'percentuale': [], 'dataset': []}\n",
    "\n",
    "for percentuale in percentuali_rumore:\n",
    "    dataset_sporcato = introduce_missing_data_custom(X_train.copy(), topFeaturesByImportance, percentuale)\n",
    "    \n",
    "    datasetSporcatoNULL['dataset'].append(dataset_sporcato)\n",
    "    datasetSporcatoNULL['percentuale'].append(percentuale * 100)\n",
    "    \n",
    "    # Creiamo e addestriamo il modello di Decision Tree\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(dataset_sporcato, y_train)\n",
    "\n",
    "    # Effettua le previsioni sui dati di test\n",
    "    y_pred_prob = clf.predict_proba(X_test)  # Probabilità predette\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcola le metriche di performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Calcola le curve ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob[:, 1])  # Assumendo binario e la classe positiva è la seconda\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Salva le metriche\n",
    "    metricsNUll['percentuale'].append(percentuale)\n",
    "    metricsNUll['accuracy'].append(accuracy)\n",
    "    metricsNUll['f1_score'].append(f1)\n",
    "    metricsNUll['precision'].append(precision)\n",
    "    metricsNUll['recall'].append(recall)\n",
    "    metricsNUll['fpr'].append(fpr)\n",
    "    metricsNUll['tpr'].append(tpr)\n",
    "    metricsNUll['roc_auc'].append(roc_auc)\n",
    "\n",
    "    print(f'Percentuale di rumore: {percentuale}. Accuracy: {accuracy}, AUC: {roc_auc}')\n",
    "    plot_confusion_matrix(clf)\n",
    "    \n",
    "    print('K-FOLD: ----------------------------')\n"
   ],
   "id": "df53924376e6cc95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Esecuzione Decision Tree con aggiunta di outliers",
   "id": "9316189c6338d66f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datasetSporcatoOutliers = {'percentuale': [], 'dataset': []}\n",
    "\n",
    "# Aggiungi le metriche ROC al dizionario delle metriche\n",
    "metricsOutliers = {\n",
    "    'percentuale': [],\n",
    "    'accuracy': [],\n",
    "    'f1_score': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'fpr': [],   # False Positive Rate\n",
    "    'tpr': [],   # True Positive Rate\n",
    "    'roc_auc': [] # Area Under the Curve\n",
    "}\n",
    "\n",
    "for percentuale in percentuali_rumore:\n",
    "    dataset_sporcato = introduce_outliers(X_train.copy(), topFeaturesByImportance, percentuale)  # Funzione che introduce rumore nel dataset\n",
    "\n",
    "    datasetSporcatoOutliers['dataset'].append(dataset_sporcato)\n",
    "    datasetSporcatoOutliers['percentuale'].append(percentuale*100)\n",
    "\n",
    "    # Creiamo e addestriamo il modello di Decision Tree con il dataset sporco\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(dataset_sporcato, y_train)\n",
    "\n",
    "    # Effettua le previsioni sui dati di test\n",
    "    y_pred_prob = clf.predict_proba(X_test)  # Probabilità predette\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcola le metriche di performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Calcola le curve ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob[:, 1])  # Assumendo binario e la classe positiva è la seconda\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Salva le metriche\n",
    "    metricsOutliers['percentuale'].append(percentuale)\n",
    "    metricsOutliers['accuracy'].append(accuracy)\n",
    "    metricsOutliers['f1_score'].append(f1)\n",
    "    metricsOutliers['precision'].append(precision)\n",
    "    metricsOutliers['recall'].append(recall)\n",
    "    metricsOutliers['fpr'].append(fpr)\n",
    "    metricsOutliers['tpr'].append(tpr)\n",
    "    metricsOutliers['roc_auc'].append(roc_auc)\n",
    "\n",
    "    print(f'Percentuale di rumore: {percentuale}. Accuracy: {accuracy}')\n",
    "    plot_confusion_matrix(clf)    \n",
    "\n",
    "    # Chiamata alla funzione di plot per confrontare le distribuzioni delle feature\n",
    "    plot_feature_distribution_comparison(X_train, dataset_sporcato, X.columns, topFeaturesByImportance)"
   ],
   "id": "11ca9d438184fa2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3 Esecuzione Decision Tree con aggiunta di righe duplicate",
   "id": "f8d0ee1d82cc5f47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datasetSporcatoDuplicate = {'percentuale': [], 'dataset': []}\n",
    "\n",
    "metricsDuplicate = {\n",
    "    'percentuale': [],\n",
    "    'accuracy': [],\n",
    "    'f1_score': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'fpr': [],   # False Positive Rate\n",
    "    'tpr': [],   # True Positive Rate\n",
    "    'roc_auc': [] # Area Under the Curve\n",
    "}\n",
    "\n",
    "for percentuale in percentuali_rumore:\n",
    "    dataset_sporcato, y_train_sporcata = introduce_duplicate_rows(X_train.copy(), percentuale, y_train.copy())  # Funzione che introduce rumore nel dataset\n",
    "\n",
    "    datasetSporcatoDuplicate['dataset'].append(dataset_sporcato)\n",
    "    datasetSporcatoDuplicate['percentuale'].append(percentuale*100)\n",
    "\n",
    "    # Creiamo e addestriamo il modello di Decision Tree con il dataset sporco\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(dataset_sporcato, y_train_sporcata)\n",
    "\n",
    "    # Effettua le previsioni sui dati di test\n",
    "    y_pred_prob = clf.predict_proba(X_test)  # Probabilità predette\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcola le metriche di performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Calcola le curve ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob[:, 1])  # Assumendo binario e la classe positiva è la seconda\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Salva le metriche\n",
    "    metricsDuplicate['percentuale'].append(percentuale)\n",
    "    metricsDuplicate['accuracy'].append(accuracy)\n",
    "    metricsDuplicate['f1_score'].append(f1)\n",
    "    metricsDuplicate['precision'].append(precision)\n",
    "    metricsDuplicate['recall'].append(recall)\n",
    "    metricsDuplicate['fpr'].append(fpr)\n",
    "    metricsDuplicate['tpr'].append(tpr)\n",
    "    metricsDuplicate['roc_auc'].append(roc_auc)\n",
    "\n",
    "    print(f'Percentuale di rumore: {percentuale}. Accuracy: {accuracy}')\n",
    "\n",
    "    # Chiamata alla funzione di plot per confrontare le distribuzioni delle feature\n",
    "    plot_confusion_matrix(clf)\n",
    "    plot_feature_distribution_comparison(X_train, dataset_sporcato, X.columns, topFeaturesByImportance)"
   ],
   "id": "1b8a45c4587b10c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Analisi dell'impatto del rumore su feature specifiche del dataset\n",
    "In questa sezione andremo ad analizzare quanto impatta sul dataset la presenza di rumore su una feature. In particolare lo andremo a studiare singolarmente su quelle più importanti (prima l'aggiunta del rumore avvenita su tutte le top 5 feature, mentre adesso andiamo ad aggiungerlo a feature specifiche)"
   ],
   "id": "a1c7fb3b0fc9f011"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.1 Definizione delle funzioni per l'aggiunta di rumore in una feature specifica\n",
    "Vengono utilizzate le stesse funzioni create precedentemente per l'aggiunta di rumore\n"
   ],
   "id": "cdb0a6496d0dfbdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def addestro_e_genero_plot(FEATURE_TO_EVALUATE, percentuali_rumore):\n",
    "    num_percentuali = len(percentuali_rumore)\n",
    "\n",
    "    # Configura la grandezza della figura in base al numero di percentuali\n",
    "    if num_percentuali == 1:\n",
    "        fig_width, fig_height = 12, 8  # Dimensioni più grandi per un singolo grafico\n",
    "        font_size = 14\n",
    "        rows = 1\n",
    "        cols = 1\n",
    "    else:\n",
    "        cols = 3  # Numero di colonne nel layout\n",
    "        rows = (num_percentuali + cols - 1) // cols  # Calcola il numero di righe necessarie\n",
    "        fig_width, fig_height = cols * 5, rows * 4\n",
    "        font_size = 10\n",
    "\n",
    "    plt.figure(figsize=(fig_width, fig_height))  # Dimensione della figura\n",
    "\n",
    "    for i, percentuale in enumerate(percentuali_rumore):\n",
    "        # Introduci i dati mancanti\n",
    "        dataset_sporcato = introduce_missing_data_custom(X_train.copy(), FEATURE_TO_EVALUATE, percentuale)\n",
    "\n",
    "        # Allena il modello\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "        model.fit(dataset_sporcato, y_train)\n",
    "\n",
    "        # Calcola l'accuratezza sui dati di test\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Ottieni l'importanza delle caratteristiche\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        # Evidenzia le caratteristiche sporcate\n",
    "        feature_importance_df['Highlight'] = feature_importance_df['Feature'].isin(FEATURE_TO_EVALUATE)\n",
    "\n",
    "        # Crea una sottotrama per ogni percentuale\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "\n",
    "        # Usa `hue` per colorare le barre e rimuovi la legenda automatica\n",
    "        sns.barplot(x='Importance', y='Feature', data=feature_importance_df, hue='Highlight', palette={False: '#1f77b4', True: '#ffeb3b'}, dodge=False, legend=False)\n",
    "\n",
    "        # Aggiungi l'accuratezza al titolo del grafico\n",
    "        plt.title(f'Accuratezza: {accuracy:.2f}\\nPercentuale: {percentuale}%', fontsize=font_size)\n",
    "        plt.xlabel('Importanza', fontsize=font_size)\n",
    "        plt.ylabel('Caratteristica', fontsize=font_size)\n",
    "        plt.xticks(fontsize=font_size)\n",
    "        plt.yticks(fontsize=font_size)\n",
    "\n",
    "    plt.tight_layout()  # Ottimizza il layout\n",
    "    plt.show()"
   ],
   "id": "8d9cf325fab460cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.2 Analisi del modello con le feature sporcate di valori NULLI",
   "id": "e76541c12f6a2075"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6.2.1 Base per il nostro test\n",
    "In questa sezione viene mostrata la base per il nostro test, eseguendo l'algoritmo sul dataset senza rumore, per vedere quali feature vengono considerate più importanti."
   ],
   "id": "858d52d9c70a1c0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FEATURE_TO_EVALUATE = [] # Lista vuota per non aggiungere rumore\n",
    "percentuali_rumore = [0] # 0% per non aggiungere rumore\n",
    "\n",
    "addestro_e_genero_plot(FEATURE_TO_EVALUATE, percentuali_rumore)"
   ],
   "id": "abf6cc9661f0dc27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6.2.2 Aggiunta di rumore alla feature \"radius_worst\"\n",
    "Possiamo notare dal grafico precedente che la feature \"radius_worst\" è la più importante. In questa sezione andiamo ad aggiungere rumore solo a questa feature per vedere come cambia l'importanza delle feature."
   ],
   "id": "ea9d323825f64a31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FEATURE_TO_EVALUATE = ['radius_worst']\n",
    "percentuali_rumore = [0.001, 0.002, 0.003, 0.006, 0.01, 1] \n",
    "\n",
    "addestro_e_genero_plot(FEATURE_TO_EVALUATE, percentuali_rumore)"
   ],
   "id": "8c59560ede8bc261",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Possiamo notare che all'aumentare della percentuale di rumore, l'importanza della feature \"radius_worst\" diminuisce. Questo è dovuto al fatto che il rumore aggiunto alla feature \"radius_worst\" rende il modello meno affidabile rispetto alla feature \"radius_worst\" stessa. Notiamo, inoltre, che l'importanza della feature perimeter_worst aumenta e l'accuratezza del modello aumenta di conseguenza, possiamo quindi ipotizzare che dallo 0.6% di rumore all'1% di rumore il modello ha deciso di non considerare più radius_worst come feature importante, ma di basarsi su perimeter_worst.\n",
    "E' interessante anche notare l'aumento dell'accuratezza appena l'algoritmo non considera più radius_worst come feature importante."
   ],
   "id": "247e23049c429877"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6.2.3 Aggiunta di rumore alla feature \"perimeter_worst\" e \"radius_worst\"",
   "id": "8a21ab960edb508e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FEATURE_TO_EVALUATE = ['radius_worst', 'perimeter_worst']\n",
    "percentuali_rumore = [0.003, 0.004, 0.005,  0.01,  0.02, 1]\n",
    "\n",
    "addestro_e_genero_plot(FEATURE_TO_EVALUATE, percentuali_rumore)"
   ],
   "id": "8798f20c54758a98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Possiamo notare un comportamento simile a quello precedentemente studiato, ma con la differenza che a 100% di rumore su entrambe le feature l'algoritmo inizia a calare di accuratezza. Questo ci fa capire che l'algoritmo non è in grado di gestire un rumore così elevato su due feature importanti.\n",
    "Andiamo adesso a studiare cosa succede se continuiamo a sporcare feature in un dataset"
   ],
   "id": "d2bd8634218bb0e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6.2.4 Aggiunta di rumore su un numero elavato di feature",
   "id": "66e31ac30a231520"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FEATURE_TO_EVALUATE = ['radius_worst', 'perimeter_worst', 'area_worst', 'concave points_worst', 'concave points_mean', 'concavity_mean', 'area_mean', 'perimeter_mean', 'radius_mean', 'area_se']\n",
    "percentuali_rumore = [0.1,  0.2, 0.3, 0.4, 0.5, 1]\n",
    "\n",
    "addestro_e_genero_plot(FEATURE_TO_EVALUATE, percentuali_rumore)"
   ],
   "id": "63982b6eb49b31c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Possiamo notare che nonostante il Binary tree sia un algoritmo molto robusto e consolidato per la classificazione con il numero di feature che abbiamo sporcato (pari a 10) l'accuratezza del modello è calata drasticamente per una qualsiasi percentuale di rumore al di sopra del 40%, cosa del tutto normale direi, ma ci fa capire l'importanza di un dataset pulito per l'addestramento di un modello.",
   "id": "5a7797cf93069602"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.3 Analisi del modello con le feature sporcate di OUTLIERS",
   "id": "5ffa3c5ad5390b27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5ba1ca28e8497b2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#################################################################################################################",
   "id": "1700864633aee874"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Conclusione e grafici riassuntivi",
   "id": "9dfe50c8603cecf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.1 Grafico Decision Tree con valori nulli",
   "id": "8e8c5fa1ade2df61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Converti il dizionario in DataFrame\n",
    "metrics_df = pd.DataFrame(metricsNUll)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='accuracy', label='accuracy', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='f1_score', label='f1Score', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='precision', label='precision', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='recall', label='recall', marker='o')\n",
    "\n",
    "plt.title('Andamento dataset Breast Cancer Wisconsin con Decision Tree e valori nulli')\n",
    "plt.xlabel('Percentuale di rumore')\n",
    "plt.ylabel('Valore')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "ef554f655e55595a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.2 Grafico Decision Tree con outliers",
   "id": "bdec26f03d1fb026"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Converti il dizionario in DataFrame\n",
    "metrics_df = pd.DataFrame(metricsOutliers)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='accuracy', label='accuracy', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='f1_score', label='f1Score', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='precision', label='precision', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='recall', label='recall', marker='o')\n",
    "\n",
    "plt.title('Andamento dataset Breast Cancer Wisconsin con Decision Tree e outliers')\n",
    "plt.xlabel('Percentuale di rumore')\n",
    "plt.ylabel('Valore')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "15652787f98c8437"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.3 Grafico Decision Tree con righe duplicate",
   "id": "92a0beb297df4913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Converti il dizionario in DataFrame\n",
    "metrics_df = pd.DataFrame(metricsDuplicate)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='accuracy', label='accuracy', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='f1_score', label='f1Score', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='precision', label='precision', marker='o')\n",
    "sns.lineplot(data=metrics_df, x='percentuale', y='recall', label='recall', marker='o')\n",
    "\n",
    "plt.title('Andamento dataset Breast Cancer Wisconsin con Decision Tree e valori duplicati')\n",
    "plt.xlabel('Percentuale di rumore')\n",
    "plt.ylabel('Valore')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "8df69b3f9b4812bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.4 Curva ROC",
   "id": "3dbf21bcc5cc5d78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Crea una figura con 3 subplot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Funzione per tracciare la curva ROC\n",
    "def plot_roc_curve(ax, metrics, title):\n",
    "    for i, percentuale in enumerate(metrics['percentuale']):\n",
    "        ax.plot(metrics['fpr'][i], metrics['tpr'][i], label=f'ROC curve (noise {percentuale}%) (AUC = {metrics[\"roc_auc\"][i]:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Plot delle curve ROC per ciascuna condizione\n",
    "plot_roc_curve(axs[0], metricsNUll, 'ROC for Null Data')\n",
    "plot_roc_curve(axs[1], metricsOutliers, 'ROC for Outliers')\n",
    "plot_roc_curve(axs[2], metricsDuplicate, 'ROC for Duplicates')\n",
    "\n",
    "# Mostra la figura\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b6f749f535b05b78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
